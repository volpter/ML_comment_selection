{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/volpter/ML_comment_selection/blob/main/NLP_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import joblib"
      ],
      "metadata": {
        "id": "qyVpk8tzKpi2"
      },
      "id": "qyVpk8tzKpi2",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7c1d655b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c1d655b",
        "outputId": "38ef6bd7-96f7-4acc-bf9e-c8542dbaa9c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, precision_recall_curve, plot_precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fddb8b64",
      "metadata": {
        "id": "fddb8b64"
      },
      "outputs": [],
      "source": [
        "main_df = pd.read_csv('labeled.csv', sep =',' )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "22b0d5c8",
      "metadata": {
        "id": "22b0d5c8"
      },
      "outputs": [],
      "source": [
        "main_df.toxic = main_df.toxic.apply(lambda x: int(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "088b9538",
      "metadata": {
        "id": "088b9538"
      },
      "outputs": [],
      "source": [
        "train_X, test_X, train_y, test_y = train_test_split(main_df.comment, main_df.toxic, random_state=42, test_size=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "328ee62a",
      "metadata": {
        "id": "328ee62a"
      },
      "outputs": [],
      "source": [
        "stemmer=SnowballStemmer(language='russian')\n",
        "def preprocess(comment):\n",
        "    t_com = word_tokenize(comment, language='russian')\n",
        "    t_com = [t for t in t_com if t not in string.punctuation ]\n",
        "    t_com = [t for t in t_com if t not in stopwords.words('russian')]\n",
        "    t_com = [stemmer.stem(i) for i in t_com]\n",
        "    return (t_com)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train_X.apply(preprocess)\n",
        "test_X = test_X.apply(preprocess)"
      ],
      "metadata": {
        "id": "5Z_bXB6nMAoP"
      },
      "id": "5Z_bXB6nMAoP",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unite(l:list):\n",
        "  temp = ''\n",
        "  for i in range(len(l)):\n",
        "    temp+=l[i]\n",
        "    temp+=' '\n",
        "  temp = temp[:-2]\n",
        "  return (temp)"
      ],
      "metadata": {
        "id": "cJYpLpkaVJFY"
      },
      "id": "cJYpLpkaVJFY",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set= train_X.apply(unite)\n",
        "test_set = test_X.apply(unite)"
      ],
      "metadata": {
        "id": "wuuuTt2zVCN2"
      },
      "id": "wuuuTt2zVCN2",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "7fa1ba47",
      "metadata": {
        "id": "7fa1ba47"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "model_pipeline = Pipeline([\n",
        "                          ('vectorizer', vectorizer),\n",
        "                          ('model', LogisticRegression(random_state=42))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param = [{ 'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
        "          'vectorizer__norm': ('l1', 'l2', None),\n",
        "          'model__solver': ['newton-cg', 'lbfgs', 'sag'],\n",
        "          'model__penalty': ['none', 'l2']\n",
        "    \n",
        "}]\n",
        "gridsearcher = GridSearchCV(model_pipeline, param, cv=2, verbose=1)"
      ],
      "metadata": {
        "id": "yU2c0kCWMxKt"
      },
      "id": "yU2c0kCWMxKt",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gridsearcher.fit(train_set, train_y)"
      ],
      "metadata": {
        "id": "mcF6V9nmQU-T"
      },
      "id": "mcF6V9nmQU-T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gridsearcher.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka5Ik4jYYRYh",
        "outputId": "288b9792-49e4-417a-ae8a-0a46dc901860"
      },
      "id": "Ka5Ik4jYYRYh",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model__penalty': 'none',\n",
              " 'model__solver': 'sag',\n",
              " 'vectorizer__ngram_range': (1, 1),\n",
              " 'vectorizer__norm': 'l1'}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = gridsearcher.best_estimator_\n",
        "joblib.dump(model, 'model.pkl')"
      ],
      "metadata": {
        "id": "fztR3wuiYE8P"
      },
      "id": "fztR3wuiYE8P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = joblib.load('model.pkl')\n"
      ],
      "metadata": {
        "id": "PHl8psC8aAlA"
      },
      "id": "PHl8psC8aAlA",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(test_set)\n",
        "print (precision_score(prediction, test_y), recall_score(prediction, test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytUzk5BXaJ8J",
        "outputId": "b51bedba-4dfb-4c13-c644-ec1b34fa21d0"
      },
      "id": "ytUzk5BXaJ8J",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7412935323383084 0.8097826086956522\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "NLP project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}